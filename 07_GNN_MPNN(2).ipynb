{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Ho7QzWvk8IcB",
      "metadata": {
        "id": "Ho7QzWvk8IcB"
      },
      "source": [
        "#### Google Colab compatible version\n",
        "The following setup is suitable for Google Colab with T4 GPU.\n",
        "\n",
        "To enable T4 GPU: Connect configuration menu $\\rightarrow$ Change runtime type $\\rightarrow$ Hardware accelerator: T4 GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "RWInpnEv7_d9",
      "metadata": {
        "id": "RWInpnEv7_d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3225c960-860c-46cc-df5a-471c0f3d60a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ml2024-25'...\n",
            "remote: Enumerating objects: 151, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 151 (delta 24), reused 20 (delta 17), pack-reused 116 (from 1)\u001b[K\n",
            "Receiving objects: 100% (151/151), 37.37 MiB | 16.58 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/gmum/ml2024-25.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "zAjf4bUx42z8",
      "metadata": {
        "id": "zAjf4bUx42z8"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/ml2024-25')  # This ensures import lab.checker later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e670bf640f110540",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e670bf640f110540",
        "outputId": "7ec4dc94-39c9-486a-9483-f8b699dec96e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.0%2Bcu121-cp310-cp310-linux_x86_64.whl (799.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m799.1/799.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.19.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.0%2Bcu121-cp310-cp310-linux_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.0%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m837.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19.0) (11.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.24.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.24.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.24.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n",
            "    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.5.1+cu121\n",
            "    Uninstalling torchaudio-2.5.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.5.1+cu121\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0+cu121 torchaudio-2.4.0+cu121 torchvision-0.19.0+cu121 triton-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "aQPY-MIt8VaW",
      "metadata": {
        "id": "aQPY-MIt8VaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66aa13e-2feb-4b70-e680-fcfebae4a9c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/torch-2.4/cu121/repo.html\n",
            "Collecting dgl\n",
            "  Downloading https://data.dgl.ai/wheels/torch-2.4/cu121/dgl-2.4.0%2Bcu121-cp310-cp310-manylinux1_x86_64.whl (355.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.2/355.2 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.4.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from dgl) (24.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgl) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.10.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from dgl) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.67.1)\n",
            "Requirement already satisfied: torch<=2.4.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.4.0+cu121)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<=2.4.0->dgl) (12.6.85)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<=2.4.0->dgl) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<=2.4.0->dgl) (1.3.0)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-2.4.0+cu121\n"
          ]
        }
      ],
      "source": [
        "!pip install  dgl -f https://data.dgl.ai/wheels/torch-2.4/cu121/repo.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Yoyd-1nt8XVQ",
      "metadata": {
        "id": "Yoyd-1nt8XVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9476436e-6373-42de-d7c1-7276b4c8b4c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgllife\n",
            "  Downloading dgllife-0.3.2-py3-none-any.whl.metadata (667 bytes)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgllife) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgllife) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgllife) (3.4.2)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (from dgllife) (0.2.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.4.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (2024.12.14)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->dgllife) (3.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (1.17.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (3.1.0)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (0.10.9.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2024.2)\n",
            "Downloading dgllife-0.3.2-py3-none-any.whl (226 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/226.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dgllife\n",
            "Successfully installed dgllife-0.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install dgllife"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "kx1Y0mtj8ZRA",
      "metadata": {
        "id": "kx1Y0mtj8ZRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8e4a0e6-c1f2-4d3d-d8b5-e8cc3743a819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.11)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/pyg_lib-0.4.0%2Bpt24cu121-cp310-cp310-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_scatter-2.1.2%2Bpt24cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_sparse-0.6.18%2Bpt24cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_cluster-1.6.3%2Bpt24cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt24cu121-cp310-cp310-linux_x86_64.whl (986 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m986.2/986.2 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.26.4)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.4.0+pt24cu121 torch_cluster-1.6.3+pt24cu121 torch_scatter-2.1.2+pt24cu121 torch_sparse-0.6.18+pt24cu121 torch_spline_conv-1.2.2+pt24cu121\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cu121.html  # Optional dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "mrO7asE88-My",
      "metadata": {
        "id": "mrO7asE88-My",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a8bc8f8-d900-47b9-dc12-b0d2ffdaaaa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit==2022.3.5\n",
            "  Downloading rdkit-2022.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit==2022.3.5) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit==2022.3.5) (11.1.0)\n",
            "Downloading rdkit-2022.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.0/37.0 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2022.3.5\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit==2022.3.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "mjrdsp9W8fTr",
      "metadata": {
        "id": "mjrdsp9W8fTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c39a186e-e307-4ccb-db50-aa29f0d7fd0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.4.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.9 torchmetrics-1.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bec6577a3d2a155",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "9bec6577a3d2a155"
      },
      "source": [
        "# Graph Neural Networks (GNNs)\n",
        "## Part I: Message Passing Neural Networks (MPNNs)\n",
        "We are going to implement few MPNNs for molecular property prediciton. It's recommended that you're familiar with the recent lectures on GNNs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a10f517285d85363",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "a10f517285d85363"
      },
      "source": [
        "# Packages for GNNs\n",
        "There two very popular packages for GNNs that uses pytorch as a backend:\n",
        "1. [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html).\n",
        "2. [Deep Graph Library](https://www.dgl.ai/pages/start.html) (along with [dgl-lifesci](https://lifesci.dgl.ai/install/index.html).\n",
        "The former is more stable, the latter has a convenient extension [dgl-lifesci](https://lifesci.dgl.ai/generated/dgllife.utils.CanonicalAtomFeaturizer.html) for molecular data and is generally much more user-friendly. For convenience, we are going to use all three packages, so install appropriate versions of them, please (I recommend installing with pip). If you have issues with installing rdkit (required by dgl-lifesci), you can install rdkit using pip (pip install rdkit)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46af56ed",
      "metadata": {
        "id": "46af56ed"
      },
      "source": [
        "## Installation commands\n",
        "The following commands should work for the `ml` conda env from the `01_zasady_wstep.ipynb`.\n",
        "\n",
        "```\n",
        "conda install -c dglteam/label/cu117 dgl\n",
        "conda install -c conda-forge dgllife\n",
        "conda install pyg -c pyg\n",
        "\n",
        "conda install libboost=1.73.0 boost=1.73.0 boost-cpp=1.73.0\n",
        "pip install rdkit==2022.3.5\n",
        "\n",
        "conda install -c conda-forge torchmetrics\n",
        "conda install -c conda-forge wandb\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61eff200e2fa43b4",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "61eff200e2fa43b4"
      },
      "source": [
        "# Molecular graphs\n",
        "(Copied from [mldd23 repository](https://github.com/gmum/mldd23/blob/main/labs/L3-graph-neural-networks/laboratory.ipynb))\n",
        "In mathematics, a graph is an object that consists of a set of vertices (nodes) connected with edges, i.e. $\\mathcal{G} = (V, E)$, where $V = \\{ v_i: i \\in \\{1, 2, \\dots, N \\} \\}$ and $E \\subseteq \\{ (v_i, v_j):\\, v_i,v_j \\in V \\}$.\n",
        "\n",
        "Molecular graphs are a special class of graphs, where besides nodes (denoting atoms) and edges (denoting chemical bonds), we have an additional information about atom types and sometimes also bond types. We can assume that we have an additional set of node/atom features encoded as a matrix $X$, where $X_{ij}$ is the $j$-th feature of the $i$-th atom. As atomic features, we can have one-hot encoded atom symbols (a vector containing zeros on all positions besides the position that corresponds to the atom symbol), the number of implicit hydrogens bonded with this atom, or the number of heavy neighbors (atoms other than hydrogens bonded to the given atom).\n",
        "\n",
        "Egdes/bonds can be encoded in two different ways. One method is to use an adjacency matrix $A$, where $A_{ij}=1$ if nodes/atoms $v_i$ nad $v_j$ are connected ($A_{ij}=0$ otherwise). In the case of sparse matrices, a more useful encoding is a list of pairs of connected atoms (a list of index pairs). This latter enocding is used by the PyTorch-Geometric library.\n",
        "\n",
        "In practice, a molecular graph can be described by two matrices: $X \\in \\mathbb{R}^{N \\times F}$ and $E \\in \\{0, 1,\\dots,N-1\\}^{2 \\times N}$, where $N$ is the number of atoms, and $F$ is the number of atomic features.\n",
        "<img src=\"resources/mol_graph.png\" height=\"500\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7533978cf98913d",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "7533978cf98913d"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7eeba76a4a89736",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "f7eeba76a4a89736"
      },
      "source": [
        "We are going to use FreeSolv dataset that contains 642 hydration free energy values for small molecules. The goal is to predict the [hydration free energy](https://en.wikipedia.org/wiki/Hydration_energy) of a given molecule. It's a very commonly used dataset for benchmarking molecular property prediction models. It's small, so we can minimize our co2 footprint and time spent on training.\n",
        "\n",
        "Molecules in most chemical datasets are represented with SMILES. SMILES is a linearization of the molecular graph, it's pretty convenient and can even be used as an input to text-based models. Fortunately, dgllife provides a fancy FreeSolv dataset wrapper that will 1) transform the SMILES into a molecular graph, and 2) encode the nodes and edges with some sensible chemical features (like atom types, bond type etc.) with node and edge features, so we don't really need to care about it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e6b97de5d9371cf2",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "b85f2060732c4dda914930263425b3ed",
            "dd484fbb5d4446158de7d0d3154e44dd",
            "06879a8da0f14725a6a4a2e9e00de4b4",
            "82180e06f64d49eebfb70301a198c7f3",
            "028e16199c0f45e18e0fa6e665272d6f",
            "1caa87e9b10b477cafcf1d7febeb507e",
            "25dbb9fcc990460fa234063870affbf1",
            "5dffe493298a4f3681da635c09e4ecd8",
            "4f01ed4d7b62425e9c60b6e944462760",
            "4712dbea45c34e009f8bede5b68c8999",
            "a3b11166de0b4d878e14ed409087f858"
          ]
        },
        "id": "e6b97de5d9371cf2",
        "outputId": "f288d2d3-84e9-4891-df36-bfbb62c490c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "Downloading /root/.dgl/FreeSolv.zip from https://data.dgl.ai/dataset/FreeSolv.zip...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/root/.dgl/FreeSolv.zip:   0%|          | 0.00/11.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b85f2060732c4dda914930263425b3ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting file to /root/.dgl/FreeSolv\n",
            "Processing dgl graphs from scratch...\n"
          ]
        }
      ],
      "source": [
        "from dgllife.utils import (CanonicalAtomFeaturizer,\n",
        "                           CanonicalBondFeaturizer,\n",
        "                           SMILESToBigraph)\n",
        "from dgllife.data import FreeSolv\n",
        "import torch\n",
        "import dgl\n",
        "\n",
        "node_featurizer = CanonicalAtomFeaturizer()\n",
        "edge_featurizer = CanonicalBondFeaturizer(self_loop=True)\n",
        "dataset = FreeSolv(\n",
        "    smiles_to_graph=SMILESToBigraph(\n",
        "        node_featurizer=node_featurizer,\n",
        "        edge_featurizer=edge_featurizer,\n",
        "        add_self_loop=True, # well... some of the molecules in the dataset contain no edges, so adding the self-loop (edge from node to itself) makes the future MPNN implementations simpler.\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bf700b3346f6a31",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "9bf700b3346f6a31"
      },
      "source": [
        "## Playground"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fd08f424238c9580",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "fd08f424238c9580",
        "outputId": "f2ec1a69-bc37-4d44-cc91-8aa72705f939",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('CN(C)C(=O)c1ccc(cc1)OC',\n",
              " Graph(num_nodes=13, num_edges=39,\n",
              "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
              "       edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)}),\n",
              " tensor([-11.0100]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "smiles, graph, label = dataset[0]\n",
        "smiles, graph, label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b297de83ea20e626",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "b297de83ea20e626"
      },
      "source": [
        "We see that the dataset item consist of a SMILES string, a graph, and a label. The graph is a [DGLGraph](https://docs.dgl.ai/en/0.8.x/api/python/dgl.DGLGraph.html) object that contains node and edge features. We can access them with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f6cd6aafddd20202",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "f6cd6aafddd20202",
        "outputId": "9d5fa112-14d2-46ef-b573-21e932cb4bbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 74])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "graph.ndata['h'].shape  # node features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "972195282cdfb48f",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "972195282cdfb48f",
        "outputId": "aef3f59b-e537-43f3-a689-0b6ce1b1f5b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([39, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "graph.edata['e'].shape  # edge features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bf1af8de0703b2d3",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "bf1af8de0703b2d3",
        "outputId": "49124d31-4567-4313-faf4-de3bb2dedf13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[12,  0],\n",
              "        [ 0, 12],\n",
              "        [ 0,  2],\n",
              "        [ 2,  0],\n",
              "        [ 0,  4],\n",
              "        [ 4,  0],\n",
              "        [ 4,  7],\n",
              "        [ 7,  4],\n",
              "        [ 4,  9],\n",
              "        [ 9,  4],\n",
              "        [ 9,  6],\n",
              "        [ 6,  9],\n",
              "        [ 6, 10],\n",
              "        [10,  6],\n",
              "        [10, 11],\n",
              "        [11, 10],\n",
              "        [11,  3],\n",
              "        [ 3, 11],\n",
              "        [ 3,  8],\n",
              "        [ 8,  3],\n",
              "        [11,  5],\n",
              "        [ 5, 11],\n",
              "        [ 5,  1],\n",
              "        [ 1,  5],\n",
              "        [ 8,  9],\n",
              "        [ 9,  8],\n",
              "        [ 0,  0],\n",
              "        [ 1,  1],\n",
              "        [ 2,  2],\n",
              "        [ 3,  3],\n",
              "        [ 4,  4],\n",
              "        [ 5,  5],\n",
              "        [ 6,  6],\n",
              "        [ 7,  7],\n",
              "        [ 8,  8],\n",
              "        [ 9,  9],\n",
              "        [10, 10],\n",
              "        [11, 11],\n",
              "        [12, 12]], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "start_nodes, end_nodes = graph.edges()  # edges. Note that edges are directed, so we have two edges for each bond. Moreover, we have self-loops, to easily handle molecules with only one atom.\n",
        "edges = torch.stack([start_nodes, end_nodes], dim=1)\n",
        "edges"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "611ba9d29599927d",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "611ba9d29599927d"
      },
      "source": [
        "Importantly, if we want to create a batch of graphs, we can simply treat the graphs as... a single graph with many disconnected components. The reason is that MPNN cannot pass the message between disconnected compontents, so the graphs in a batch won't influence each other. To make a batch from two graphs, we can simply run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "1063ec4d70a6c648",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "1063ec4d70a6c648",
        "outputId": "80bbc9dc-6a57-42a3-f8d1-fac37a5118dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Graph(num_nodes=13, num_edges=39,\n",
              "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
              "       edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)}),\n",
              " Graph(num_nodes=5, num_edges=13,\n",
              "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
              "       edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)}),\n",
              " Graph(num_nodes=18, num_edges=52,\n",
              "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
              "       edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)}))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "_, graph_1, _ = dataset[0]\n",
        "_, graph_2, _ = dataset[1]\n",
        "collated_graph = dgl.batch([graph_1, graph_2])\n",
        "graph_1, graph_2, collated_graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cd9357b97e4c3b1b",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "cd9357b97e4c3b1b",
        "outputId": "6bc5c444-3388-4ee2-d528-edd1136762a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([13,  5], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "collated_graph.batch_num_nodes()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b37a35a6ae91e55d",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "b37a35a6ae91e55d"
      },
      "source": [
        "In the collated_graph, the ids corresponding to the nodes of graph_2 are shifted by the size of graph_1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7598293d45c78c0",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "7598293d45c78c0",
        "outputId": "99931a73-8d97-46ef-9cc0-322b9986feee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=torch.int32),\n",
              " tensor([0, 1, 2, 3, 4], dtype=torch.int32),\n",
              " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
              "        dtype=torch.int32))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "graph_1.nodes(), graph_2.nodes(), collated_graph.nodes()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e67b6515649fa77d",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "e67b6515649fa77d"
      },
      "source": [
        "## Split\n",
        "We are going to make our split slightly harder by using [scaffold](https://hub.knime.com/infocom/extensions/jp.co.infocom.cheminfo.jchem.feature/latest/jp.co.infocom.cheminfo.jchem.bemismurckoclustering.BemisMurckoClusteringNodeFactory) (scaffold is the largest cycle in a molecule) splitting that puts molecules with similar scaffolds to the same split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "901db3d9cdc5a748",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "901db3d9cdc5a748",
        "outputId": "1b1395bc-b928-4d26-955a-5e0fc59fff9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start initializing RDKit molecule instances...\n",
            "Start computing Bemis-Murcko scaffolds.\n"
          ]
        }
      ],
      "source": [
        "from dgllife.utils import ScaffoldSplitter\n",
        "\n",
        "splitter = ScaffoldSplitter()\n",
        "train, valid, test = splitter.train_val_test_split(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6a601dc47074ca6",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "b6a601dc47074ca6"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be6593567ea5467",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "be6593567ea5467"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e75cf00937a3c413",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "e75cf00937a3c413"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "from tqdm.autonotebook import tqdm\n",
        "from dgl.dataloading import GraphDataLoader\n",
        "from torchmetrics import Metric\n",
        "from dgl.data import Subset\n",
        "from torch import nn\n",
        "from typing import Type\n",
        "from typing import Dict, Any\n",
        "from pathlib import Path\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "\n",
        "\n",
        "class LoggerBase(ABC):\n",
        "    def __init__(self, logdir: str | Path):\n",
        "        self.logdir = Path(logdir)\n",
        "        self.logdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    @abstractmethod\n",
        "    def log_metrics(self, metrics: Dict[str, Any], prefix: str):\n",
        "        ...\n",
        "\n",
        "    @abstractmethod\n",
        "    def close(self):\n",
        "        ...\n",
        "\n",
        "\n",
        "class DummyLogger(LoggerBase):  # If you don't want to use any logger, you can use this one\n",
        "    def log_metrics(self, metrics: Dict[str, Any], prefix: str):\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        pass\n",
        "\n",
        "    def restart(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class MetricList:\n",
        "    def __init__(self, metrics: Dict[str, Metric]):\n",
        "        self.metrics = copy.deepcopy(metrics)\n",
        "\n",
        "    def update(self, preds: torch.Tensor, targets: torch.Tensor) -> None:\n",
        "        for name, metric in self.metrics.items():\n",
        "            metric.update(preds.detach().cpu(), targets.cpu())\n",
        "\n",
        "    def compute(self) -> Dict[str, float]:\n",
        "        metrics = {}\n",
        "        for name, metric_fn in self.metrics.items():\n",
        "            metrics[name] = metric_fn.compute().item()\n",
        "            metric_fn.reset()\n",
        "        return metrics\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(\n",
        "            self,\n",
        "            *,\n",
        "            run_dir: str | Path,\n",
        "            train_dataset: Subset,\n",
        "            valid_dataset: Subset,\n",
        "            train_metrics: Dict[str, Metric],\n",
        "            valid_metrics: Dict[str, Metric],\n",
        "            model: nn.Module,\n",
        "            logger: LoggerBase,\n",
        "            optimizer_kwargs: Dict[str, Any],\n",
        "            optimizer_cls: Type[torch.optim.Optimizer] = torch.optim.Adam,\n",
        "            n_epochs: int,\n",
        "            train_batch_size: int = 32,\n",
        "            valid_batch_size: int = 16,\n",
        "            device: str = \"cuda\",\n",
        "            valid_every_n_epochs: int = 1,\n",
        "            loss_fn=nn.MSELoss()\n",
        "    ):\n",
        "        self.run_dir = Path(run_dir)\n",
        "        self.train_loader = GraphDataLoader(\n",
        "            dataset=train_dataset,\n",
        "            batch_size=train_batch_size,\n",
        "            shuffle=True,\n",
        "        )\n",
        "        self.valid_loader = GraphDataLoader(\n",
        "            dataset=valid_dataset,\n",
        "            batch_size=valid_batch_size,\n",
        "            shuffle=True,\n",
        "        )\n",
        "        self.train_metrics = MetricList(train_metrics)\n",
        "        self.valid_metrics = MetricList(valid_metrics)\n",
        "        self.logger = logger\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer_cls(model.parameters(), **optimizer_kwargs)\n",
        "        self.n_epochs = n_epochs\n",
        "        self.device = device\n",
        "        self.valid_every_n_epochs = valid_every_n_epochs\n",
        "        self.loss_fn = loss_fn\n",
        "        self.model.to(device)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validate(self, dataloader: GraphDataLoader, prefix: str) -> Dict[str, float]:\n",
        "        previous_mode = self.model.training\n",
        "        self.model.eval()\n",
        "        losses = []\n",
        "        for _, graphs, labels in dataloader:\n",
        "            graphs = graphs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            preds = self.model(graphs)\n",
        "            loss = self.loss_fn(preds, labels)\n",
        "            losses.append(loss.item())\n",
        "            self.valid_metrics.update(preds, labels)\n",
        "        self.model.train(mode=previous_mode)\n",
        "        metrics = {\"loss\": np.mean(losses)} | self.valid_metrics.compute()\n",
        "        self.logger.log_metrics(metrics=metrics, prefix=prefix)\n",
        "        return metrics\n",
        "\n",
        "    def train(self) -> Dict[str, float]:\n",
        "        self.model.train()\n",
        "        valid_metrics = {}\n",
        "        for epoch in tqdm(range(self.n_epochs), total=self.n_epochs):\n",
        "            for _, graphs, labels in self.train_loader:\n",
        "                self.optimizer.zero_grad()\n",
        "                graphs = graphs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                preds = self.model(graphs)\n",
        "                loss = self.loss_fn(preds, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                self.train_metrics.update(preds, labels)\n",
        "                train_metrics = {\"loss\": loss.item()} | self.train_metrics.compute()\n",
        "                self.logger.log_metrics(metrics=train_metrics, prefix=\"train\")\n",
        "\n",
        "                if epoch % self.valid_every_n_epochs == 0 or epoch == self.n_epochs - 1:\n",
        "                    valid_metrics = self.validate(self.valid_loader, prefix=\"valid\")\n",
        "\n",
        "        return valid_metrics\n",
        "\n",
        "    def test(self, dataset: Subset) -> Dict[str, float]:\n",
        "        dataloader = GraphDataLoader(\n",
        "            dataset=dataset,\n",
        "            batch_size=16,\n",
        "            shuffle=False,\n",
        "        )\n",
        "        return self.validate(dataloader, prefix=\"test\")\n",
        "\n",
        "    def close(self):  # close the logger, not really required for wandb\n",
        "        self.logger.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d54c9a1e68cd221",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "7d54c9a1e68cd221"
      },
      "source": [
        "# Graph Neural Networks (GNNs)\n",
        "The high-level Graph Neural Network architecture we are going to use looks roughly like this:\n",
        "\n",
        "<img src=\"resources/gnn.png\" width=\"1200\" />\n",
        "\n",
        "- The Featurizer takes a molecule and transforms it to a graph with node and edge features (it happens at the level of dataset, so we don't really need to worry about that).\n",
        "- In our case, we will linearly embed the node and edge features to the hidden size before applying first MPNN layer which is not captured in the diagram.\n",
        "- The MPNN layer takes node (and possibly edge embeddings) and the graph structure and returns updated node embeddings. It happens in a loop.\n",
        "- Then the node embeddings are aggregated by the Readout layer to obtain a graph embeddings.\n",
        "- Finally, the graph embeddings are passed to the MLP to obtain the final prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e6e7df76cc963d8b",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "e6e7df76cc963d8b"
      },
      "outputs": [],
      "source": [
        "class MPNNLayerBase(ABC, nn.Module):\n",
        "    def _init(self, hidden_size: int):\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            hidden_size: the size of node (and edges) embeddings\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                edge_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "\n",
        "class ReadoutBase(nn.Module):\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 node_features_size: int,\n",
        "                 edge_features_size: int,\n",
        "                 hidden_size: int,\n",
        "                 output_size: int,\n",
        "                 mpnn_layer_cls: Type[MPNNLayerBase],\n",
        "                 mpnn_layer_kwargs: Dict[str, Any],\n",
        "                 mpnn_n_layers: int,\n",
        "                 readout_cls: Type[ReadoutBase]):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_features_size: the size of node features\n",
        "            edge_features_size: the size of edge features\n",
        "            hidden_size: the size of node (and edge) embeddings\n",
        "            output_size: the size of the final prediction\n",
        "            mpnn_layer_cls: the class of MPNN layer\n",
        "            mpnn_layer_kwargs: the kwargs for the MPNN layer\n",
        "            mpnn_n_layers: the number of MPNN layers\n",
        "            readout_cls: the class of Readout layer\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.linear_node = nn.Linear(node_features_size, hidden_size)\n",
        "        self.linear_edge = nn.Linear(edge_features_size, hidden_size)\n",
        "        self.mpnn_layers = nn.ModuleList([\n",
        "            mpnn_layer_cls(hidden_size=hidden_size, **mpnn_layer_kwargs)\n",
        "            for _ in range(mpnn_n_layers)\n",
        "        ])\n",
        "        self.readout = readout_cls(hidden_size=hidden_size)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_size, output_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            graph: a DGLGraph that contains the graph structure and node/edge features in a sparse format\n",
        "        Returns:\n",
        "            predictions: the final predictions\n",
        "        \"\"\"\n",
        "        node_embeddings, edge_embeddings = graph.ndata['h'], graph.edata['e']\n",
        "        node_embeddings = self.linear_node(node_embeddings)\n",
        "        edge_embeddings = self.linear_edge(\n",
        "            edge_embeddings)  # some of the models does not use edge features, but we won't use if-clauses for convenience.\n",
        "        for layer in self.mpnn_layers:\n",
        "            node_embeddings = layer(node_embeddings=node_embeddings, edge_embeddings=edge_embeddings, graph=graph)\n",
        "        graph_embedding = self.readout(node_embeddings, graph)\n",
        "        predictions = self.mlp(graph_embedding)\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9ac59d947b4000b",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "b9ac59d947b4000b"
      },
      "source": [
        "## Readout\n",
        "Readout operation is used to aggregate node embeddings to obtain a graph embedding. There are many different readout operations, but the most popular are: sum, mean, attention, and max. We are going to implement the first three of them. Summing over nodes' embeddings seems trivial, but they're stored in a sparse format, meaning that all the nodes form all the graphs in a batch are stored in a one tensor of size `[num_nodes_1 + num_nodes_2 + ... + num_nodes_N, hidden_size]':   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "473300e58a6023b7",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "473300e58a6023b7",
        "outputId": "4c2cb5a9-a59b-4673-be5d-19bea0383f73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([23, 16]), tensor([13,  5,  5], dtype=torch.int32))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "batched_graph = dgl.batch([dataset[0][1], dataset[1][1], dataset[2][1]])\n",
        "linear = nn.Linear(node_featurizer.feat_size(), 16)\n",
        "node_embeddings = linear(batched_graph.ndata['h'])\n",
        "node_embeddings.shape, batched_graph.batch_num_nodes()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fce302b7c444ae16",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "fce302b7c444ae16"
      },
      "source": [
        "For simplicity, we will convert the sparse node embeddings to a dense format with padding. Then the shape of the node embeddings will be `[batch_size, max_num_nodes, hidden_size]`. We can use the `to_dense_batch` function from `torch_geometric` for that:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a3fd81a5384d2ad0",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "a3fd81a5384d2ad0"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "\n",
        "\n",
        "def to_dense_embeddings(node_embeddings: torch.Tensor,\n",
        "                        graph: dgl.DGLGraph,\n",
        "                        fill_value: float = 0.0) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Converts sparse node embeddings to dense node embeddings with padding.\n",
        "    Arguments:\n",
        "        node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        graph: a batch of graphs\n",
        "        fill_value: a value to fill the padding with\n",
        "    Returns:\n",
        "        node_embeddings: node embeddings in a dense format, i.e. [batch_size, max_num_nodes, hidden_size]\n",
        "        mask: a mask indicating which nodes are real and which are padding, i.e. [batch_size, max_num_nodes]\n",
        "    \"\"\"\n",
        "    num_nodes = graph.batch_num_nodes() # e.g. [2, 3, 3]\n",
        "    indices = torch.arange(len(num_nodes), device=num_nodes.device)\n",
        "    batch = torch.repeat_interleave(indices, num_nodes).long() # e.g. [0, 0, 1, 1, 1, 2, 2, 2]\n",
        "    return to_dense_batch(node_embeddings, batch,\n",
        "                          fill_value=fill_value)  # that's the only reason we have torch_geometric in the requirements\n",
        "\n",
        "\n",
        "def to_sparse_embeddings(node_embeddings: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Converts dense node embeddings to sparse node embeddings.\n",
        "    Arguments:\n",
        "        node_embeddings: node embeddings in a dense format, i.e. [batch_size, max_num_nodes, hidden_size]\n",
        "        mask: a mask indicating which nodes are real and which are padding, i.e. [batch_size, max_num_nodes]\n",
        "    Returns:\n",
        "        node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "    \"\"\"\n",
        "    return node_embeddings[mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4190f0ff3fa0ae1f",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "4190f0ff3fa0ae1f"
      },
      "source": [
        "Now, we can simply convert the node embeddings to a dense format and sum them $x = \\sum_i^n x_i$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "841a8932a12397f3",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "841a8932a12397f3"
      },
      "outputs": [],
      "source": [
        "class SumReadout(ReadoutBase):\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        # We can also use dgl.sum_nodes function, but let assume it's forbidden in that notebook ;)\n",
        "        node_embeddings, _ = to_dense_embeddings(node_embeddings, graph)\n",
        "        return node_embeddings.sum(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "447a28b93e6e8e89",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "447a28b93e6e8e89"
      },
      "outputs": [],
      "source": [
        "def test_readout(readout_cls: Type[ReadoutBase], expected_output: torch.Tensor):\n",
        "    torch.manual_seed(0)\n",
        "    graph = dgl.batch([dataset[0][1], dataset[1][1], dataset[2][1]])\n",
        "    linear = nn.Linear(node_featurizer.feat_size(), 16)\n",
        "    node_embeddings = linear(graph.ndata['h'])\n",
        "    readout = readout_cls(hidden_size=16)\n",
        "    result = readout(node_embeddings, graph)\n",
        "    assert torch.allclose(result, expected_output, atol=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b5dd5e1b3bbde2cc",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "b5dd5e1b3bbde2cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "abb95905-6627-4422-e6a5-4fb64d616333"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'expected_sum_readout' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-c0e875d83c19>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_readout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSumReadout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_sum_readout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'expected_sum_readout' is not defined"
          ]
        }
      ],
      "source": [
        "test_readout(SumReadout, expected_sum_readout)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "579fd18386daaed",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "579fd18386daaed"
      },
      "source": [
        "### Task 1. Implement mean readout (1 point).\n",
        "Implement the mean readout given by formula $x = \\frac{1}{n}\\sum_i^n x_i$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "13bd85d993f87d63",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "13bd85d993f87d63"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import dgl\n",
        "\n",
        "class MeanReadout(ReadoutBase):\n",
        "    def forward(\n",
        "        self,\n",
        "        node_embeddings: torch.Tensor,  # Shape: [total_num_nodes, hidden_size]\n",
        "        graph: dgl.DGLGraph            # Graph containing structure\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            node_embeddings: Node embeddings in sparse format (total_num_nodes, hidden_size)\n",
        "            graph: A DGLGraph containing the graph structure\n",
        "\n",
        "        Returns:\n",
        "            graph_embeddings: Mean readout of shape [batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        # Compute the mean of node embeddings for each graph in the batch\n",
        "        graph_embeddings = dgl.mean_nodes(graph, feat=node_embeddings)\n",
        "        return graph_embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db68abdbc2736d7a",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "db68abdbc2736d7a"
      },
      "source": [
        "### Task 2. Implement attention readout (2 points).\n",
        "Implement the attention readout given by formula $x = \\sum_i^n \\frac{\\exp(score_i))}{\\sum_j^n \\exp(score_j)}x_i$, where $score_i=score\\_mlp(x_i)$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "6c1f5bcdbc90881",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "6c1f5bcdbc90881"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import dgl\n",
        "\n",
        "class AttentionReadout(ReadoutBase):\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__(hidden_size)\n",
        "        self.score_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_size, 1),  # Outputs a scalar score per node\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        node_embeddings: torch.Tensor,  # Shape: [total_num_nodes, hidden_size]\n",
        "        graph: dgl.DGLGraph             # Graph containing structure\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            node_embeddings: Node embeddings in a sparse format, i.e., [total_num_nodes, hidden_size].\n",
        "            graph: A DGLGraph that contains the graph structure.\n",
        "\n",
        "        Returns:\n",
        "            graph_embeddings: Graph embeddings of shape [batch_size, hidden_size].\n",
        "        \"\"\"\n",
        "        # Compute scores for each node using score_mlp\n",
        "        scores = self.score_mlp(node_embeddings)  # Shape: [total_num_nodes, 1]\n",
        "\n",
        "        # Apply softmax over nodes within each graph in the batch\n",
        "        attention_weights = dgl.softmax(scores, graph.batch_num_nodes())  # Shape: [total_num_nodes, 1]\n",
        "\n",
        "        # Compute attention-weighted sum of node embeddings\n",
        "        node_embeddings_weighted = node_embeddings * attention_weights  # Shape: [total_num_nodes, hidden_size]\n",
        "        graph_embeddings = dgl.sum_nodes(graph, feat=node_embeddings_weighted)  # Shape: [batch_size, hidden_size]\n",
        "\n",
        "        return graph_embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac465a3b9279474b",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ac465a3b9279474b"
      },
      "source": [
        "## Message Passing Neural Networks (MPNNs)\n",
        "Message Passing is given by formula:\n",
        "$$\n",
        "x'_i=\\rho(x_i, \\square_{j\\in N(i)} \\psi(x_j, x_i, e_{ji})),\n",
        "$$\n",
        "where $\\psi$ is learnable message function, $\\rho$ is learnable update, and $\\square$ is aggregation function. $N(i)$ denotes the set of neighbors of node $i$. Note that in our dataset we added self-loops to every node, so $N(i)$ also contains $i$, but we don't bother with that."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "307c236e3cb84e76",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "307c236e3cb84e76"
      },
      "source": [
        "### Simple MPNN\n",
        "For instance, we can define a very simple MPNN layer by the following formula:\n",
        "$$\n",
        "x'_i=W_1x_i + W_2\\sum_{j\\in N(i)} W_3x_j,\n",
        "$$\n",
        "where W_i are linear layers with implicit bias term (we will make the bias implicit in every formula in that notebook). Let us implement this simple MPNN:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "f11f284c299831ed",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "f11f284c299831ed"
      },
      "outputs": [],
      "source": [
        "class SimpleMPNNLayer(MPNNLayerBase):\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear_1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_3 = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                edge_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "        # graph is bi-directed, so we can freely swap the \"start\" and \"end\" meanings\n",
        "        start_nodes, end_nodes = graph.edges(order='srcdst') # using this `order` value sorts the `start_nodes`\n",
        "        messages = self.linear_3(node_embeddings[end_nodes]) # W_3x_j\n",
        "        message_dense, _ = to_dense_batch(messages, start_nodes.long(), fill_value=0.0) # to make the life easier, we convert the node embeddings to dense representation\n",
        "        aggregated_message = message_dense.sum(dim=1) # \\sum_{j\\in N(i)} W_3x_j\n",
        "        aggregated_message = self.linear_2(aggregated_message) # W_2\\sum_{j\\in N(i)} W_3x_j\n",
        "        node_embeddings = self.linear_1(node_embeddings) + aggregated_message # W_1x_i + W_2\\sum_{j\\in N(i)} W_3x_j\n",
        "        return node_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "8767bffa62008f67",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "8767bffa62008f67"
      },
      "outputs": [],
      "source": [
        "def test_mpnn_layer(mpnn_layer_cls: Type[MPNNLayerBase], expected_output: torch.Tensor):\n",
        "    torch.manual_seed(0)\n",
        "    graph = dgl.batch([dataset[0][1], dataset[1][1]])\n",
        "    linear_nodes = nn.Linear(node_featurizer.feat_size(), 4)\n",
        "    linear_edges = nn.Linear(edge_featurizer.feat_size(), 4)\n",
        "    node_embeddings = linear_nodes(graph.ndata['h'])\n",
        "    edge_embeddings = linear_edges(graph.edata['e'])\n",
        "    layer = mpnn_layer_cls(hidden_size=4)\n",
        "    result = layer(node_embeddings, edge_embeddings, graph)\n",
        "    assert torch.allclose(result, expected_output, atol=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "461980b684728501",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "461980b684728501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "429e4f77-4cbe-4735-ad7f-6087d7178295"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'expected_simple_mpnn_output' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-510c96afd5aa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_mpnn_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimpleMPNNLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_simple_mpnn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'expected_simple_mpnn_output' is not defined"
          ]
        }
      ],
      "source": [
        "test_mpnn_layer(SimpleMPNNLayer, expected_simple_mpnn_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0dbbc2f2efa8ca2",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "d0dbbc2f2efa8ca2"
      },
      "source": [
        "### Task 3. Implement GraphSAGE layer (2 points).\n",
        "Implement a GraphSAGE given by the following formula:\n",
        "$$\n",
        "x'_i=W_1x_i + W_2\\frac{1}{deg(i)}\\sum_{j\\in N(i)} x_j,\n",
        "$$\n",
        "where $deg(i) = #N(i)$ is the number of neighbors of node $i$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "82528a8dacf24cd3",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "82528a8dacf24cd3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import dgl\n",
        "\n",
        "class SAGELayer(MPNNLayerBase):\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear_1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_2 = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        node_embeddings: torch.Tensor,  # Shape: [total_num_nodes, hidden_size]\n",
        "        edge_embeddings: torch.Tensor,  # Not used in this layer\n",
        "        graph: dgl.DGLGraph             # Graph containing the structure\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: Node embeddings in a sparse format, i.e., [total_num_nodes, hidden_size].\n",
        "            edge_embeddings: Edge embeddings in a sparse format, i.e., [total_num_edges, hidden_size].\n",
        "            graph: A DGLGraph that contains the graph structure.\n",
        "\n",
        "        Returns:\n",
        "            node_embeddings: Updated node embeddings in a sparse format, i.e., [total_num_nodes, hidden_size].\n",
        "        \"\"\"\n",
        "        # Step 1: Aggregate neighbor embeddings (mean of neighbors)\n",
        "        graph.ndata['h'] = node_embeddings  # Assign node features\n",
        "        graph.update_all(\n",
        "            message_func=dgl.function.copy_u('h', 'm'),  # Copy node embeddings to messages\n",
        "            reduce_func=dgl.function.mean('m', 'neigh')  # Compute mean of neighbors\n",
        "        )\n",
        "        neigh_embeddings = graph.ndata['neigh']  # Shape: [total_num_nodes, hidden_size]\n",
        "\n",
        "        # Step 2: Apply W1 to self embeddings\n",
        "        self_embeddings = self.linear_1(node_embeddings)  # Shape: [total_num_nodes, hidden_size]\n",
        "\n",
        "        # Step 3: Apply W2 to aggregated neighbor embeddings\n",
        "        neighbor_embeddings = self.linear_2(neigh_embeddings)  # Shape: [total_num_nodes, hidden_size]\n",
        "\n",
        "        # Step 4: Combine the two contributions\n",
        "        updated_embeddings = self_embeddings + neighbor_embeddings  # Shape: [total_num_nodes, hidden_size]\n",
        "\n",
        "        return updated_embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea8735b272ecad46",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ea8735b272ecad46"
      },
      "source": [
        "### Task 4. Implement GIN layer (2 points).\n",
        "Implement a GIN layer given by the following formula:\n",
        "$$\n",
        "x'_i=mlp((1 + \\epsilon)x_i + \\sum_{j\\in N(i)} x_j).\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "e422bea1856fc29",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "e422bea1856fc29"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import dgl\n",
        "\n",
        "class GINLayer(MPNNLayerBase):\n",
        "    def __init__(self, hidden_size: int, eps: float = 0.0):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.eps = nn.Parameter(torch.tensor(eps, dtype=torch.float32))  # Make eps learnable\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        node_embeddings: torch.Tensor,  # Shape: [total_num_nodes, hidden_size]\n",
        "        edge_embeddings: torch.Tensor,  # Not used for GIN\n",
        "        graph: dgl.DGLGraph             # Graph structure\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: Node embeddings in a sparse format, i.e., [total_num_nodes, hidden_size]\n",
        "            edge_embeddings: Edge embeddings in a sparse format, i.e., [total_num_edges, hidden_size]\n",
        "            graph: A DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            node_embeddings: Updated node embeddings in a sparse format, i.e., [total_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "        # Step 1: Aggregate neighbor embeddings (sum of neighbors)\n",
        "        graph.ndata['h'] = node_embeddings\n",
        "        graph.update_all(\n",
        "            message_func=dgl.function.copy_u('h', 'm'),  # Copy node embeddings to messages\n",
        "            reduce_func=dgl.function.sum('m', 'neigh')   # Sum neighbor embeddings\n",
        "        )\n",
        "        neigh_embeddings = graph.ndata['neigh']  # Shape: [total_num_nodes, hidden_size]\n",
        "\n",
        "        # Step 2: Apply the formula (1 + eps) * self embeddings + neighbor embeddings\n",
        "        self_embeddings = (1 + self.eps) * node_embeddings\n",
        "        combined_embeddings = self_embeddings + neigh_embeddings  # Shape: [total_num_nodes, hidden_size]\n",
        "\n",
        "        # Step 3: Pass through MLP\n",
        "        updated_embeddings = self.mlp(combined_embeddings)  # Shape: [total_num_nodes, hidden_size]\n",
        "\n",
        "        return updated_embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fe4ec2134b539da",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "9fe4ec2134b539da"
      },
      "source": [
        "### Task 5. Implement GINE layer (2 points).\n",
        "Implement a GINE layer given by the following formula:\n",
        "$$\n",
        "x'_i=mlp((1 + \\epsilon)x_i + \\sum_{j\\in N(i)} ReLU(x_j + e_{ji})).\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "635e6bcb4e40fdd2",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "635e6bcb4e40fdd2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import dgl\n",
        "\n",
        "class GINELayer(MPNNLayerBase):\n",
        "    def __init__(self, hidden_size: int, eps: float = 0.0):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.eps = nn.Parameter(torch.tensor(eps, dtype=torch.float32))  # Umożliwiamy uczenie eps\n",
        "        self.relu = nn.ReLU()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        node_embeddings: torch.Tensor,  # [total_num_nodes, hidden_size]\n",
        "        edge_embeddings: torch.Tensor,  # [total_num_edges, hidden_size]\n",
        "        graph: dgl.DGLGraph\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: Embeddingi węzłów w formacie rzadkim, [total_num_nodes, hidden_size]\n",
        "            edge_embeddings: Embeddingi krawędzi w formacie rzadkim, [total_num_edges, hidden_size]\n",
        "            graph: Obiekt DGLGraph, który zawiera strukturę grafu.\n",
        "        Returns:\n",
        "            node_embeddings: Zaktualizowane embeddingi węzłów, [total_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "        # Dodanie embeddingów krawędzi do grafu\n",
        "        graph.ndata['h'] = node_embeddings\n",
        "        graph.edata['e'] = edge_embeddings\n",
        "\n",
        "        # Przesyłanie wiadomości: dodajemy x_j + e_ji z ReLU\n",
        "        graph.update_all(\n",
        "            message_func=dgl.function.u_add_e('h', 'e', 'm'),  # x_j + e_ji\n",
        "            reduce_func=dgl.function.sum(msg='m', out='neigh_sum')  # Sumowanie dla sąsiadów\n",
        "        )\n",
        "        neigh_embeddings = graph.ndata['neigh_sum']  # [total_num_nodes, hidden_size]\n",
        "\n",
        "        # ReLU na sąsiadach\n",
        "        neigh_embeddings = self.relu(neigh_embeddings)\n",
        "\n",
        "        # (1 + eps) * x_i\n",
        "        self_embeddings = (1 + self.eps) * node_embeddings\n",
        "\n",
        "        # Połączenie własnych embeddingów z sąsiadami\n",
        "        combined_embeddings = self_embeddings + neigh_embeddings\n",
        "\n",
        "        # Przejście przez MLP\n",
        "        updated_embeddings = self.mlp(combined_embeddings)\n",
        "\n",
        "        return updated_embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b220afd7f1d78b8",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "6b220afd7f1d78b8"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f465e5d378487e7",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "2f465e5d378487e7"
      },
      "source": [
        "## Logger\n",
        "We are going to use [wandb](https://wandb.ai/site) for logging. It's a very convenient tool for logging and visualizing the training process. It's free for academic use, so you can create an account and use it for your projects. If you don't want to use wandb, you can use any other online logger (like [comet.ml](https://www.comet.ml/site/)), but you need to implement the appropriate LoggerBase subclass on your own. To setup and use wandb, you need to do the following:\n",
        "1. [Setup the wandb](https://docs.wandb.ai/quickstart) (or any other online logger).\n",
        "2. Give your supervisor access to your project (ask him/her about the username.\n",
        "3. Use the logger for all your trainings and provide the links to the final runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "1462ef331426d529",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "1462ef331426d529"
      },
      "outputs": [],
      "source": [
        "class WandbLogger(LoggerBase):\n",
        "    def __init__(\n",
        "            self, logdir: str | Path, project_name: str, experiment_name: str, **kwargs: Dict[str, Any]\n",
        "    ):\n",
        "        super().__init__(logdir)\n",
        "        import wandb\n",
        "        self.project_name = project_name\n",
        "        self.experiment_name = experiment_name\n",
        "        self.kwargs = kwargs\n",
        "        self.run = wandb.init(\n",
        "            dir=self.logdir,\n",
        "            project=self.project_name,\n",
        "            name=self.experiment_name,\n",
        "            **self.kwargs,\n",
        "        )\n",
        "\n",
        "    def log_metrics(self, metrics: Dict[str, Any], prefix: str):\n",
        "        metrics = {f\"{prefix}/{k}\": v for k, v in metrics.items()}\n",
        "        self.run.log(metrics)\n",
        "\n",
        "    def close(self):\n",
        "        self.run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1db91eaab1a90175",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "1db91eaab1a90175"
      },
      "source": [
        "## Task 6. Train GraphSAGE (2 points).\n",
        "1. Tune hyperparameters of a GNN with `SAGELayer` as MPNN layer to obtain at most 2.0 MAE on the validation set. You can modify the GNN/MPNN architecture, so it uses some regularization tricks like dropout or batch norm. Don't change the validation batch size. If your validation MAE is in (2.0, 2.5], you can obtain 1 point.\n",
        "2. Report the obtained MAE on the validation and test set (only the former need to be lower than 2.0 MAE).\n",
        "3. Provide the link to the final run: [your link]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "e3e9e0cf69701d46",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "e3e9e0cf69701d46"
      },
      "outputs": [],
      "source": [
        "### Example code for training. You can modify it for easier grid-searching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "2980b66ad10a9824",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "2980b66ad10a9824"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def get_time_stamp() -> str:\n",
        "    return datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dgllife.utils import (CanonicalAtomFeaturizer, CanonicalBondFeaturizer, SMILESToBigraph)\n",
        "from dgllife.data import FreeSolv\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchmetrics import MeanAbsoluteError as MAE\n",
        "from torch.utils.data import DataLoader\n",
        "import dgl\n",
        "\n",
        "# Featurizers and dataset loading\n",
        "node_featurizer = CanonicalAtomFeaturizer()\n",
        "edge_featurizer = CanonicalBondFeaturizer(self_loop=True)\n",
        "\n",
        "dataset = FreeSolv(\n",
        "    smiles_to_graph=SMILESToBigraph(\n",
        "        node_featurizer=node_featurizer,\n",
        "        edge_featurizer=edge_featurizer,\n",
        "        add_self_loop=True,\n",
        "    )\n",
        ")\n",
        "\n",
        "# A function to create batches for the DataLoader\n",
        "def collate_fn(batch):\n",
        "    # Rozdzielenie danych na SMILES, graf i etykiety\n",
        "    smiles, graphs, labels = zip(*batch)\n",
        "\n",
        "    # Łączenie grafów w jeden obiekt DGL\n",
        "    batched_graph = dgl.batch(graphs)\n",
        "\n",
        "    # Łączenie etykiet w tensor\n",
        "    labels = torch.stack(labels, dim=0)\n",
        "\n",
        "    return batched_graph, labels\n",
        "\n",
        "# Define the DataLoader\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Example GraphSAGE model\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, node_features_size, edge_features_size, hidden_size, output_size, mpnn_layer_cls, mpnn_n_layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(mpnn_layer_cls(hidden_size))\n",
        "        for _ in range(mpnn_n_layers - 1):\n",
        "            self.layers.append(mpnn_layer_cls(hidden_size))\n",
        "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, graph, node_features):\n",
        "        for layer in self.layers:\n",
        "            node_features = layer(node_features, None, graph)\n",
        "        return self.output_layer(node_features)\n",
        "\n",
        "# Train function\n",
        "def train_model(model, train_loader, valid_loader, n_epochs, criterion, optimizer, device):\n",
        "    model.to(device)\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            graph, node_features, labels = batch\n",
        "            graph = graph.to(device)\n",
        "            node_features, labels = node_features.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(graph, node_features)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        valid_loss = 0\n",
        "        mae_metric = MAE().to(device)\n",
        "        with torch.no_grad():\n",
        "            for batch in valid_loader:\n",
        "                graph, node_features, labels = batch\n",
        "                graph = graph.to(device)\n",
        "                node_features, labels = node_features.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(graph, node_features)\n",
        "                loss = criterion(outputs, labels)\n",
        "                valid_loss += loss.item()\n",
        "                mae_metric.update(outputs, labels)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, Validation Loss: {valid_loss / len(valid_loader)}, MAE: {mae_metric.compute().item()}\")\n",
        "\n",
        "# Hyperparameters\n",
        "hidden_size = 256\n",
        "output_size = 1\n",
        "n_layers = 6\n",
        "lr = 1e-4\n",
        "n_epochs = 50\n",
        "\n",
        "# Model and optimizer\n",
        "model = GNN(\n",
        "    node_features_size=128,  # Example size, adjust as necessary\n",
        "    edge_features_size=128,  # Example size, adjust as necessary\n",
        "    hidden_size=hidden_size,\n",
        "    output_size=output_size,\n",
        "    mpnn_layer_cls=SAGELayer,  # Use GraphSAGE\n",
        "    mpnn_n_layers=n_layers\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.L1Loss()  # MAE\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "print(dataset[0])\n",
        "train_model(model, train_loader, valid_loader, n_epochs, criterion, optimizer, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "CaowuTVJw2r8",
        "outputId": "1a7a7a32-378d-4172-c70d-c9cd4be86688"
      },
      "id": "CaowuTVJw2r8",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting file to /root/.dgl/FreeSolv\n",
            "Processing dgl graphs from scratch...\n",
            "('CN(C)C(=O)c1ccc(cc1)OC', Graph(num_nodes=13, num_edges=39,\n",
            "      ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
            "      edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)}), tensor([-11.0100]))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 3, got 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-ea4fd1011632>\u001b[0m in \u001b[0;36m<cell line: 108>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-ea4fd1011632>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, valid_loader, n_epochs, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "18cd039ad8f03ca6",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "18cd039ad8f03ca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "6967954c-cd66-4305-efcf-5cdfb62fe0b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Abort",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAbort\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-db1cab45f67c>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     logger=WandbLogger(\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"runs/mpnn\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mproject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mldd23\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-caded367462c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logdir, project_name, experiment_name, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         self.run = wandb.init(\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[1;32m   1310\u001b[0m         \u001b[0;31m# Need to build delay into this sentry capture because our exit hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;31m# mess with sentry's ability to send out errors before the program ends.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# should never get here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/analytics/sentry.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self, exc)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# this will messily add this \"reraise\" function to the stack trace,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# but hopefully it's not too bad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_safe_noop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0mwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WandbInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1290\u001b[0;31m         wi.setup(\n\u001b[0m\u001b[1;32m   1291\u001b[0m             \u001b[0minit_settings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_settings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, init_settings, config, config_exclude_keys, config_include_keys, allow_val_change, monitor_gym)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_noop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             wandb_login._login(\n\u001b[0m\u001b[1;32m    290\u001b[0m                 \u001b[0manonymous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manonymous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m_login\u001b[0;34m(anonymous, key, relogin, host, force, timeout, _backend, _silent, _disable_warning, _entity)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mwlogin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwlogin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36mprompt_api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;34m\"\"\"Updates the global API key by prompting the user.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mApiKeyStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTTY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             directive = (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m_prompt_api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m                 key = apikey.prompt_api_key(\n\u001b[0m\u001b[1;32m    244\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                     \u001b[0mapi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/apikey.py\u001b[0m in \u001b[0;36mprompt_api_key\u001b[0;34m(settings, api, input_callback, browser_callback, no_offline, no_create, local)\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;34mf\"You can find your API key in your browser here: {app_url}/authorize\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             )\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_ask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mwrite_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkey\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/click/termui.py\u001b[0m in \u001b[0;36mprompt\u001b[0;34m(text, default, hide_input, confirmation_prompt, type, value_proc, prompt_suffix, show_default, err, show_choices)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/click/termui.py\u001b[0m in \u001b[0;36mprompt_func\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhide_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mecho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAbort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAbort\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torchmetrics import MeanAbsoluteError as MAE\n",
        "from torchmetrics import MeanSquaredError as MSE\n",
        "from torchmetrics import PearsonCorrCoef as PCC\n",
        "\n",
        "metrics = {\n",
        "    \"mae\": MAE(),\n",
        "    \"mse\": MSE(),\n",
        "    \"pcc\": PCC(),\n",
        "}\n",
        "\n",
        "model = GNN(\n",
        "    node_features_size=node_featurizer.feat_size(),\n",
        "    edge_features_size=edge_featurizer.feat_size(),\n",
        "    hidden_size=256,\n",
        "    output_size=1,\n",
        "    mpnn_layer_cls=SAGELayer,\n",
        "    mpnn_n_layers=6,\n",
        "    readout_cls=MeanReadout,\n",
        "    mpnn_layer_kwargs={}\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    run_dir=\"experiments\",\n",
        "    train_dataset=train,\n",
        "    valid_dataset=valid,\n",
        "    train_metrics=metrics,\n",
        "    valid_metrics=metrics,\n",
        "    train_batch_size=32,\n",
        "    model=model,\n",
        "    logger=WandbLogger(\n",
        "        logdir=\"runs/mpnn\",\n",
        "        project_name=\"mldd23\",\n",
        "        experiment_name=f\"sage_{get_time_stamp()}\",\n",
        "    ),\n",
        "    optimizer_kwargs={\"lr\": 1e-4},\n",
        "    n_epochs=50,\n",
        "    device=\"cpu\",\n",
        "    valid_every_n_epochs=1,\n",
        ")\n",
        "\n",
        "valid_metrics = trainer.train()\n",
        "test_metrics = trainer.test(test)\n",
        "trainer.close()\n",
        "print(f\"Validation metrics: {valid_metrics}\")\n",
        "print(f\"Test metrics: {test_metrics}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0acbbdb6f55d814",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "c0acbbdb6f55d814"
      },
      "source": [
        "## Task 7. Train GIN (2 points).\n",
        "1. Tune hyperparameters of a GNN with `GINLayer` as MPNN layer to obtain at most 2.0 MAE on the validation set. You can modify the GNN/MPNN architecture, so it uses some regularization tricks like dropout or batch norm. Don't change the validation batch size. If your validation MAE is in (2.0, 2.5], you can obtain 1 point.\n",
        "2. Report the obtained MAE on the validation and test set (only the former need to be lower than 2.0 MAE).\n",
        "3. Provide the link to the final run: [your link]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl\n",
        "from dgl import DGLGraph\n",
        "from dgllife.utils import CanonicalAtomFeaturizer, CanonicalBondFeaturizer, SMILESToBigraph\n",
        "from dgllife.data import FreeSolv\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torchmetrics import MeanAbsoluteError as MAE\n",
        "\n",
        "\n",
        "class GINLayer(nn.Module):\n",
        "    def __init__(self, hidden_size, eps=0.0):\n",
        "        super(GINLayer, self).__init__()\n",
        "        self.eps = eps\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, node_embeddings, graph):\n",
        "        # Agregacja sąsiedztwa\n",
        "        with graph.local_scope():\n",
        "            graph.ndata['h'] = node_embeddings\n",
        "            graph.update_all(dgl.function.copy_u('h', 'm'), dgl.function.sum('m', 'neigh'))\n",
        "            aggregated = graph.ndata['neigh']\n",
        "            return self.mlp((1 + self.eps) * node_embeddings + aggregated)\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, node_features_size, hidden_size, output_size, mpnn_layer_cls, mpnn_n_layers):\n",
        "        super(GNN, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(mpnn_layer_cls(hidden_size))\n",
        "        for _ in range(mpnn_n_layers - 1):\n",
        "            self.layers.append(mpnn_layer_cls(hidden_size))\n",
        "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, graph, node_features):\n",
        "        for layer in self.layers:\n",
        "            node_features = layer(node_features, graph)\n",
        "        return self.output_layer(node_features)\n",
        "\n",
        "# Funkcja do trenowania modelu\n",
        "def train_model(model, train_loader, valid_loader, n_epochs, criterion, optimizer, device):\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        # Trening\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            graph, labels = batch\n",
        "            graph = graph.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            node_features = graph.ndata['h'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(graph, node_features)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Walidacja\n",
        "        model.eval()\n",
        "        valid_loss = 0\n",
        "        mae_metric = MAE().to(device)\n",
        "        with torch.no_grad():\n",
        "            for batch in valid_loader:\n",
        "                graph, labels = batch\n",
        "                graph = graph.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                node_features = graph.ndata['h'].to(device)\n",
        "\n",
        "                outputs = model(graph, node_features)\n",
        "                loss = criterion(outputs, labels)\n",
        "                valid_loss += loss.item()\n",
        "                mae_metric.update(outputs, labels)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, Validation Loss: {valid_loss / len(valid_loader)}, MAE: {mae_metric.compute().item()}\")\n",
        "\n",
        "\n",
        "node_featurizer = CanonicalAtomFeaturizer()\n",
        "edge_featurizer = CanonicalBondFeaturizer(self_loop=True)\n",
        "dataset = FreeSolv(\n",
        "    smiles_to_graph=SMILESToBigraph(\n",
        "        node_featurizer=node_featurizer,\n",
        "        edge_featurizer=edge_featurizer,\n",
        "        add_self_loop=True\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Podział na trening i walidację\n",
        "train_dataset = dataset[:80]  # 80% do treningu\n",
        "valid_dataset = dataset[80:]  # 20% do walidacji\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32)\n",
        "hidden_size = 256\n",
        "output_size = 1\n",
        "n_layers = 6\n",
        "lr = 1e-4\n",
        "n_epochs = 50\n",
        "\n",
        "model = GNN(\n",
        "    node_features_size=74,  # Zmienna w zależności od rozmiaru cech atomów\n",
        "    hidden_size=hidden_size,\n",
        "    output_size=output_size,\n",
        "    mpnn_layer_cls=GINLayer,  # Użycie GINLayer\n",
        "    mpnn_n_layers=n_layers\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.L1Loss()  # MAE\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Trenowanie modelu\n",
        "train_model(model, train_loader, valid_loader, n_epochs, criterion, optimizer, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "emxZNgkPV5Wa",
        "outputId": "f40140bc-35ab-402c-dd3f-4c3bce6993de"
      },
      "id": "emxZNgkPV5Wa",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'dgl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-da3f5c3138c8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDGLGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dgl'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "100ee2cd44877b2c",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "100ee2cd44877b2c"
      },
      "source": [
        "## Task 8. Train GINE (2 points).\n",
        "1. Tune hyperparameters of a GNN with `GINELayer` as MPNN layer to obtain at most 2.0 MAE on the validation set. You can modify the GNN/MPNN architecture, so it uses some regularization tricks like dropout or batch norm. Don't change the validation batch size. If your validation MAE is in (2.0, 2.5], you can obtain 1 point.\n",
        "2. Report the obtained MAE on the validation and test set (only the former need to be lower than 2.0 MAE).\n",
        "3. Provide the link to the final run: [your link]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl\n",
        "from dgllife.utils import CanonicalAtomFeaturizer, CanonicalBondFeaturizer, SMILESToBigraph\n",
        "from dgllife.data import FreeSolv\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torchmetrics import MeanAbsoluteError as MAE\n",
        "\n",
        "class GINELayer(nn.Module):\n",
        "    def __init__(self, hidden_size, eps=0.0):\n",
        "        super(GINELayer, self).__init__()\n",
        "        self.eps = eps\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, node_embeddings, edge_embeddings, graph):\n",
        "        with graph.local_scope():\n",
        "            graph.ndata['h'] = node_embeddings\n",
        "            graph.edata['e'] = edge_embeddings\n",
        "            graph.update_all(dgl.function.copy_u('h', 'm'), dgl.function.sum('m', 'neigh'))\n",
        "            aggregated = graph.ndata['neigh']\n",
        "            return self.mlp((1 + self.eps) * node_embeddings + F.relu(aggregated + graph.edata['e']))\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, node_features_size, edge_features_size, hidden_size, output_size, mpnn_layer_cls, mpnn_n_layers):\n",
        "        super(GNN, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(mpnn_layer_cls(hidden_size))\n",
        "        for _ in range(mpnn_n_layers - 1):\n",
        "            self.layers.append(mpnn_layer_cls(hidden_size))\n",
        "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, graph, node_features, edge_features):\n",
        "        for layer in self.layers:\n",
        "            node_features = layer(node_features, edge_features, graph)\n",
        "        return self.output_layer(node_features)\n",
        "\n",
        "\n",
        "# Funkcja do trenowania modelu\n",
        "def train_model(model, train_loader, valid_loader, n_epochs, criterion, optimizer, device):\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        # Trening\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            graph, node_features, edge_features, labels = batch\n",
        "            graph = graph.to(device)\n",
        "            node_features, edge_features, labels = node_features.to(device), edge_features.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(graph, node_features, edge_features)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Walidacja\n",
        "        model.eval()\n",
        "        valid_loss = 0\n",
        "        mae_metric = MAE().to(device)\n",
        "        with torch.no_grad():\n",
        "            for batch in valid_loader:\n",
        "                graph, node_features, edge_features, labels = batch\n",
        "                graph = graph.to(device)\n",
        "                node_features, edge_features, labels = node_features.to(device), edge_features.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(graph, node_features, edge_features)\n",
        "                loss = criterion(outputs, labels)\n",
        "                valid_loss += loss.item()\n",
        "                mae_metric.update(outputs, labels)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, Validation Loss: {valid_loss / len(valid_loader)}, MAE: {mae_metric.compute().item()}\")\n",
        "\n",
        "node_featurizer = CanonicalAtomFeaturizer()\n",
        "edge_featurizer = CanonicalBondFeaturizer(self_loop=True)\n",
        "dataset = FreeSolv(\n",
        "    smiles_to_graph=SMILESToBigraph(\n",
        "        node_featurizer=node_featurizer,\n",
        "        edge_featurizer=edge_featurizer,\n",
        "        add_self_loop=True\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Podział na trening i walidację\n",
        "train_dataset = dataset[:80]  # 80% do treningu\n",
        "valid_dataset = dataset[80:]  # 20% do walidacji\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32)\n",
        "hidden_size = 256\n",
        "output_size = 1\n",
        "n_layers = 6\n",
        "lr = 1e-4\n",
        "n_epochs = 50\n",
        "\n",
        "model = GNN(\n",
        "    node_features_size=74,  # Zmienna w zależności od rozmiaru cech atomów\n",
        "    edge_features_size=13,  # Zmienna w zależności od rozmiaru cech krawędzi\n",
        "    hidden_size=hidden_size,\n",
        "    output_size=output_size,\n",
        "    mpnn_layer_cls=GINELayer,  # Użycie GINELayer\n",
        "    mpnn_n_layers=n_layers\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.L1Loss()  # MAE\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Trenowanie modelu\n",
        "train_model(model, train_loader, valid_loader, n_epochs, criterion, optimizer, device)\n"
      ],
      "metadata": {
        "id": "g2lrflaKWiof"
      },
      "id": "g2lrflaKWiof",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "802615e3afaddf44",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "802615e3afaddf44"
      },
      "source": [
        "# Code optimization\n",
        "Some pieces of code were written suboptimally. Your task is to slightly optimize them."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17c64785b23a2b1d",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "17c64785b23a2b1d"
      },
      "source": [
        "## Task 9. Optimize SumReadout (1 point).\n",
        "`SumReadout` was written using `to_dense_embeddings` function which does some unecessary memory allocations and computations. Your task is to rewrite the method using code from a bare torch library. Hint: `torch.index_add`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "292cb0197e977862",
      "metadata": {
        "is_executing": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "292cb0197e977862",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "7569bd4d-3514-41ef-fa03-94688e18e24e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ReadoutBase' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-80d24d06efa6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mOptimizedSumReadout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReadoutBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     def forward(self,\n\u001b[1;32m      3\u001b[0m                 \u001b[0mnode_embeddings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 graph: dgl.DGLGraph) -> torch.Tensor:\n\u001b[1;32m      5\u001b[0m         \"\"\"\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ReadoutBase' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import dgl\n",
        "\n",
        "class OptimizedSumReadout(ReadoutBase):\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Optimized SumReadout that aggregates node embeddings by summing them.\n",
        "\n",
        "        Args:\n",
        "            node_embeddings (torch.Tensor): Node embeddings in a sparse format,\n",
        "                                             shape [total_num_nodes, hidden_size].\n",
        "            graph (dgl.DGLGraph): A DGLGraph that contains the graph structure.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Graph embeddings of shape [batch_size, hidden_size].\n",
        "        \"\"\"\n",
        "        batch_size = graph.batch_size\n",
        "        hidden_size = node_embeddings.size(1)\n",
        "\n",
        "        graph_embeddings = torch.zeros(batch_size, hidden_size, device=node_embeddings.device)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            batch_mask = graph.batch_num_nodes(i)\n",
        "            node_indices = graph.nodes(i).squeeze()\n",
        "\n",
        "            graph_embeddings[i] = torch.index_add(graph_embeddings[i], 0, node_indices, node_embeddings[node_indices])\n",
        "\n",
        "        return graph_embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4be6a2ed6011b64",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "d4be6a2ed6011b64"
      },
      "source": [
        "## Task 10. Optimize MeanReadout (1 point).\n",
        "Your task is to rewrite the method using code from a bare torch library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9baf5944d7ad42c2",
      "metadata": {
        "is_executing": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "9baf5944d7ad42c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "d2c6950f-5054-4ebc-edf8-4dfa455f8bc2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ReadoutBase' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-70d702fe8b98>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mOptimizedMeanReadout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReadoutBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     def forward(self,\n\u001b[1;32m      3\u001b[0m                 \u001b[0mnode_embeddings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 graph: dgl.DGLGraph) -> torch.Tensor:\n\u001b[1;32m      5\u001b[0m         \"\"\"\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ReadoutBase' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import dgl\n",
        "\n",
        "class OptimizedMeanReadout(ReadoutBase):\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Optimized MeanReadout that aggregates node embeddings by averaging them.\n",
        "\n",
        "        Args:\n",
        "            node_embeddings (torch.Tensor): Node embeddings in a sparse format,\n",
        "                                             shape [total_num_nodes, hidden_size].\n",
        "            graph (dgl.DGLGraph): A DGLGraph that contains the graph structure.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Graph embeddings of shape [batch_size, hidden_size].\n",
        "        \"\"\"\n",
        "        batch_size = graph.batch_size\n",
        "        hidden_size = node_embeddings.size(1)\n",
        "\n",
        "        graph_embeddings = torch.zeros(batch_size, hidden_size, device=node_embeddings.device)\n",
        "\n",
        "        node_counts = torch.zeros(batch_size, device=node_embeddings.device)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            node_indices = graph.nodes(i).squeeze()\n",
        "\n",
        "            graph_embeddings[i] = torch.index_add(graph_embeddings[i], 0, node_indices, node_embeddings[node_indices])\n",
        "\n",
        "            node_counts[i] = node_indices.size(0)\n",
        "\n",
        "        graph_embeddings /= node_counts.view(-1, 1)\n",
        "\n",
        "        return graph_embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b0f8cab6725a285",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "6b0f8cab6725a285"
      },
      "source": [
        "## Task 11. Optimize SimpleMPNNLayer (1 point).\n",
        "We can make our implementations of `SimpleMPNNLayer` layer (and basically any other MPNN layer) slightly faster by:\n",
        "- reducing the costs of the message embedding (in the case of `SimpleMPNNLayer`, it's application of `self.linear_3`) from $O(m)$ to $O(n)$, where $m$ is the number of edges in the graph and $n$ is the number of nodes.\n",
        "- removing quite expensive `to_dense_batch` call.\n",
        "\n",
        "Your task is to apply the above optimizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "862db51e45f8abf",
      "metadata": {
        "is_executing": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "862db51e45f8abf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "25e43564-98f7-4d06-903c-3b60e20b903d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'dgl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-690718a1b2a2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mOptimizedSimpleMPNNLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMPNNLayerBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dgl'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import dgl\n",
        "\n",
        "class OptimizedSimpleMPNNLayer(MPNNLayerBase):\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear_1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_3 = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                edge_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Optimized Simple MPNN Layer.\n",
        "\n",
        "        Arguments:\n",
        "            node_embeddings: Node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            edge_embeddings: Edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
        "            graph: A DGLGraph that contains the graph structure\n",
        "\n",
        "        Returns:\n",
        "            node_embeddings: Updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "\n",
        "        node_msgs = self.linear_1(node_embeddings)  # [num_nodes, hidden_size]\n",
        "\n",
        "\n",
        "        with graph.local_scope():\n",
        "            graph.ndata['h'] = node_msgs\n",
        "            graph.edata['e'] = edge_embeddings\n",
        "\n",
        "            graph.update_all(message_func=dgl.function.u_add_e('h', 'e', 'm'),\n",
        "                             reduce_func=dgl.function.sum('m', 'h'))\n",
        "\n",
        "\n",
        "            node_msgs = graph.ndata['h']\n",
        "\n",
        "        node_embeddings = self.linear_2(node_msgs)  # [num_nodes, hidden_size]\n",
        "        node_embeddings = self.linear_3(node_embeddings)  # [num_nodes, hidden_size]\n",
        "\n",
        "        return node_embeddings\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b85f2060732c4dda914930263425b3ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd484fbb5d4446158de7d0d3154e44dd",
              "IPY_MODEL_06879a8da0f14725a6a4a2e9e00de4b4",
              "IPY_MODEL_82180e06f64d49eebfb70301a198c7f3"
            ],
            "layout": "IPY_MODEL_028e16199c0f45e18e0fa6e665272d6f"
          }
        },
        "dd484fbb5d4446158de7d0d3154e44dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1caa87e9b10b477cafcf1d7febeb507e",
            "placeholder": "​",
            "style": "IPY_MODEL_25dbb9fcc990460fa234063870affbf1",
            "value": "/root/.dgl/FreeSolv.zip: 100%"
          }
        },
        "06879a8da0f14725a6a4a2e9e00de4b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dffe493298a4f3681da635c09e4ecd8",
            "max": 11306,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f01ed4d7b62425e9c60b6e944462760",
            "value": 11306
          }
        },
        "82180e06f64d49eebfb70301a198c7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4712dbea45c34e009f8bede5b68c8999",
            "placeholder": "​",
            "style": "IPY_MODEL_a3b11166de0b4d878e14ed409087f858",
            "value": " 11.3k/11.3k [00:00&lt;00:00, 210kB/s]"
          }
        },
        "028e16199c0f45e18e0fa6e665272d6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1caa87e9b10b477cafcf1d7febeb507e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25dbb9fcc990460fa234063870affbf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dffe493298a4f3681da635c09e4ecd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f01ed4d7b62425e9c60b6e944462760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4712dbea45c34e009f8bede5b68c8999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3b11166de0b4d878e14ed409087f858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}